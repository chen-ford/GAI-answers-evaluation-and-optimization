{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "读取数据"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba596b7e2e2fc189"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from keras.layers import Embedding, LSTM, Dense, Attention,Input\n",
    "from keras.src.callbacks import LambdaCallback\n",
    "import torch\n",
    "from keras.models import Model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T18:04:00.401447500Z",
     "start_time": "2024-04-03T18:04:00.387452800Z"
    }
   },
   "id": "e31d36d0424ac85b"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#不均衡采样\n",
    "def smote(X_train, y_train):\n",
    "    # Create an instance of SMOTE\n",
    "    smote = SMOTE(random_state=10)\n",
    "    # Apply SMOTE to the training data\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "    return X_train_resampled, y_train_resampled"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T17:58:01.276760Z",
     "start_time": "2024-04-03T17:57:59.990293300Z"
    }
   },
   "id": "9ce2799e24cf4e66"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# 加载本地数据集\n",
    "# X_train = pd.read_csv(r\"scale/X_train_minmaxscaler.csv\")['ChatGPT回答']\n",
    "# X_test = pd.read_csv(r\"scale/X_test_minmaxscaler.csv\")['ChatGPT回答']\n",
    "y_train = pd.read_csv(r\"data/y_train_minmaxscaler.csv\")\n",
    "y_test = pd.read_csv(r\"data/y_test_minmaxscaler.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T17:58:18.116232800Z",
     "start_time": "2024-04-03T17:58:18.067932400Z"
    }
   },
   "id": "fd8a281c906ec483"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# 构建词向量\n",
    "X_train_embedding = torch.load('data_embedding/train_embedding.pt',map_location=torch.device('cpu')).numpy()\n",
    "X_test_embedding = torch.load('data_embedding/test_embedding.pt',map_location=torch.device('cpu')).numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T17:58:23.261771600Z",
     "start_time": "2024-04-03T17:58:20.082487200Z"
    }
   },
   "id": "ca743b327e1fae51"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# smote数据均衡化\n",
    "X_train_embedding, y_train = smote(X_train_embedding, y_train)\n",
    "X_test_embedding, y_test = smote(X_test_embedding, y_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8114c5dd09ee7cb"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#改变数据形状\n",
    "X_train_embedding= torch.unsqueeze(torch.tensor(X_train_embedding),dim=1).numpy()\n",
    "X_test_embedding= torch.unsqueeze(torch.tensor(X_test_embedding),dim=1).numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T17:58:26.169350900Z",
     "start_time": "2024-04-03T17:58:25.680919400Z"
    }
   },
   "id": "2d8d3b3c232b9f36"
  },
  {
   "cell_type": "markdown",
   "source": [
    "TxtRNN模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31e51d84ab12cfd1"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 256)               1049600   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1090817 (4.16 MB)\n",
      "Trainable params: 1090817 (4.16 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# # 构建RNN模型\n",
    "# model = Sequential()\n",
    "# model.add(Input(shape=(1, 768)))\n",
    "# model.add(LSTM(256))\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "# model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T18:00:53.887163800Z",
     "start_time": "2024-04-03T18:00:53.304863400Z"
    }
   },
   "id": "c3fced400ee51dd6"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)        [(None, 1, 768)]             0         []                            \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)               (None, 1, 256)               1049600   ['input_4[0][0]']             \n",
      "                                                                                                  \n",
      " dense_11 (Dense)            (None, 1, 128)               32896     ['lstm_3[0][0]']              \n",
      "                                                                                                  \n",
      " dense_12 (Dense)            (None, 1, 128)               32896     ['lstm_3[0][0]']              \n",
      "                                                                                                  \n",
      " attention_1 (Attention)     (None, 1, 128)               0         ['dense_11[0][0]',            \n",
      "                                                                     'dense_12[0][0]']            \n",
      "                                                                                                  \n",
      " dense_13 (Dense)            (None, 1, 128)               16512     ['attention_1[0][0]']         \n",
      "                                                                                                  \n",
      " dense_14 (Dense)            (None, 1, 64)                8256      ['dense_13[0][0]']            \n",
      "                                                                                                  \n",
      " dense_15 (Dense)            (None, 1, 1)                 65        ['dense_14[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1140225 (4.35 MB)\n",
      "Trainable params: 1140225 (4.35 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 构建RNN_attention模型\n",
    "\n",
    "inputs = Input(shape=(1, 768))  # 假设输入形状为(1, 768)\n",
    "# 添加LSTM层\n",
    "lstm_layer = LSTM(256, return_sequences=True)(inputs)\n",
    "# 添加Dense层作为query和value\n",
    "query = Dense(128)(lstm_layer)\n",
    "value = Dense(128)(lstm_layer)\n",
    "# 添加Attention层\n",
    "attention = Attention()([query, value])\n",
    "\n",
    "# 添加全连接层\n",
    "dense_layer = Dense(128, activation='relu')(attention)\n",
    "output_layer = Dense(64, activation='relu')(dense_layer)\n",
    "# 添加输出层\n",
    "output = Dense(1, activation='sigmoid')(output_layer)\n",
    "# 构建模型\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "#模型结构\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T18:04:06.964251700Z",
     "start_time": "2024-04-03T18:04:06.364518600Z"
    }
   },
   "id": "aae03584f57c7f7e"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# 编译模型\n",
    "optimizer= tf.keras.optimizers.legacy.Adam(learning_rate=0.0001,decay=1e-6)#注意legacy\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T18:04:13.873546400Z",
     "start_time": "2024-04-03T18:04:13.854322900Z"
    }
   },
   "id": "f1513a3a42f0ac1d"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, logs):  \n",
    "\n",
    "    # print(f'Epoch {epoch + 1}, Loss: {logs[\"loss\"]}') \n",
    "    print(f'Epoch {epoch + 1}') \n",
    "    train_loss = logs.get('loss')  \n",
    "    val_loss = logs.get('val_loss')  \n",
    "    train_acc = logs.get('accuracy')  \n",
    "    val_acc = logs.get('val_accuracy')  \n",
    "      \n",
    "    print(f'Epoch {epoch + 1}, Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, '  \n",
    "          f'Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}')  \n",
    "    print(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T18:04:14.516522800Z",
     "start_time": "2024-04-03T18:04:14.503526400Z"
    }
   },
   "id": "595c32c5ad64d6af"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      " 145/3865 [>.............................] - ETA: 1:12 - loss: 0.1707 - accuracy: 0.7563"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[21], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# 训练模型\u001B[39;00m\n\u001B[0;32m      2\u001B[0m callback \u001B[38;5;241m=\u001B[39m LambdaCallback(on_epoch_end\u001B[38;5;241m=\u001B[39mon_epoch_end)\n\u001B[1;32m----> 3\u001B[0m history\u001B[38;5;241m=\u001B[39mmodel\u001B[38;5;241m.\u001B[39mfit(X_train_embedding, y_train, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m32\u001B[39m, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m64\u001B[39m, validation_split\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.2\u001B[39m,callbacks\u001B[38;5;241m=\u001B[39m[callback])\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:1783\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1775\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1776\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1777\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1780\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m   1781\u001B[0m ):\n\u001B[0;32m   1782\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m-> 1783\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_function(iterator)\n\u001B[0;32m   1784\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1785\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    828\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    830\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 831\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    833\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    834\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:867\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    864\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    865\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[0;32m    866\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[1;32m--> 867\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m tracing_compilation\u001B[38;5;241m.\u001B[39mcall_function(\n\u001B[0;32m    868\u001B[0m       args, kwds, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_no_variable_creation_config\n\u001B[0;32m    869\u001B[0m   )\n\u001B[0;32m    870\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_config \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    871\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[0;32m    872\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[0;32m    873\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[1;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[0;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[1;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m function\u001B[38;5;241m.\u001B[39m_call_flat(  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m    140\u001B[0m     flat_inputs, captured_inputs\u001B[38;5;241m=\u001B[39mfunction\u001B[38;5;241m.\u001B[39mcaptured_inputs\n\u001B[0;32m    141\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1264\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[0;32m   1260\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1261\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1262\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1263\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1264\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inference_function\u001B[38;5;241m.\u001B[39mflat_call(args)\n\u001B[0;32m   1265\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1266\u001B[0m     args,\n\u001B[0;32m   1267\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1268\u001B[0m     executing_eagerly)\n\u001B[0;32m   1269\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:217\u001B[0m, in \u001B[0;36mAtomicFunction.flat_call\u001B[1;34m(self, args)\u001B[0m\n\u001B[0;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mflat_call\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[0;32m    216\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 217\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m(\u001B[38;5;241m*\u001B[39margs)\n\u001B[0;32m    218\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:252\u001B[0m, in \u001B[0;36mAtomicFunction.__call__\u001B[1;34m(self, *args)\u001B[0m\n\u001B[0;32m    250\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[0;32m    251\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[1;32m--> 252\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mcall_function(\n\u001B[0;32m    253\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname,\n\u001B[0;32m    254\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[0;32m    255\u001B[0m         \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mflat_outputs),\n\u001B[0;32m    256\u001B[0m     )\n\u001B[0;32m    257\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    258\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[0;32m    259\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    260\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[0;32m    261\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[0;32m    262\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1479\u001B[0m, in \u001B[0;36mContext.call_function\u001B[1;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[0;32m   1477\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[0;32m   1478\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1479\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute(\n\u001B[0;32m   1480\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m   1481\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[0;32m   1482\u001B[0m       inputs\u001B[38;5;241m=\u001B[39mtensor_inputs,\n\u001B[0;32m   1483\u001B[0m       attrs\u001B[38;5;241m=\u001B[39mattrs,\n\u001B[0;32m   1484\u001B[0m       ctx\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   1485\u001B[0m   )\n\u001B[0;32m   1486\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1487\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m   1488\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m   1489\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1493\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[0;32m   1494\u001B[0m   )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     53\u001B[0m   \u001B[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001B[39;00m\n\u001B[0;32m     54\u001B[0m   inputs \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     55\u001B[0m       tensor_conversion_registry\u001B[38;5;241m.\u001B[39mconvert(t)\n\u001B[0;32m     56\u001B[0m       \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(t, core_types\u001B[38;5;241m.\u001B[39mTensor)\n\u001B[0;32m     57\u001B[0m       \u001B[38;5;28;01melse\u001B[39;00m t\n\u001B[0;32m     58\u001B[0m       \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m inputs\n\u001B[0;32m     59\u001B[0m   ]\n\u001B[1;32m---> 60\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[0;32m     61\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[0;32m     62\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     63\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "history=model.fit(X_train_embedding, y_train, batch_size=32, epochs=64, validation_split=0.2,callbacks=[callback])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T18:04:26.459469800Z",
     "start_time": "2024-04-03T18:04:14.918497400Z"
    }
   },
   "id": "94ef2162761578a7"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.20381513237953186\n",
      "Test accuracy: 0.800000011920929\n"
     ]
    }
   ],
   "source": [
    "# 评估模型\n",
    "score = model.evaluate(X_test_embedding, y_test, verbose=0)  \n",
    "print('Test loss:', score[0])  \n",
    "print('Test accuracy:', score[1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T10:05:17.528979800Z",
     "start_time": "2024-03-30T10:05:17.286151400Z"
    }
   },
   "id": "e9a012aadcf5e237"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    " # history.history 字典将包含每个epoch的loss和val_loss值  \n",
    "loss = history.history['loss']  \n",
    "val_loss = history.history['val_loss']\n",
    " \n",
    "# 绘制训练和验证loss曲线  \n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(loss, label='Training Loss')  \n",
    "plt.plot(val_loss, label='Validation Loss')  \n",
    "plt.title('Loss Curve')  \n",
    "plt.xlabel('Epoch')  \n",
    "plt.ylabel('Loss')  \n",
    "plt.legend()  \n",
    "\n",
    "#保存loss曲线\n",
    "plt.savefig('txtRNN_loss_curve.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb650087a31dabb9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#绘制准确率曲线\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='lower right')\n",
    "plt.savefig('txtRNN_accuracy.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b5dd824ab1b7fe11"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#模型的评价\n",
    "def evaluate_textRNN_model(model, X_test, y_test):\n",
    "\n",
    "    # Predict probabilities\n",
    "    y_pred_proba = model.predict(X_test)\n",
    "    y_pred_proba=np.squeeze(y_pred_proba,1)\n",
    "    # Predict labels\n",
    "    y_pred=np.where(y_pred_proba>0.5,1,0)\n",
    "    \n",
    "    # Calculate accuracy, precision, recall, F1-score, and AUC\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # Calculate ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "    \n",
    "    return [accuracy, precision, recall, f1, auc,fpr.tolist(), tpr.tolist()]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "825d95bcab5d785"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# # 加载模型\n",
    "# def load_model(model_name):\n",
    "#     model = tf.keras.models.load_model(model_name)\n",
    "#     return model\n",
    "\n",
    "#计算每个模型的评价指标,bp和svm模型需要单独计算\n",
    "metrics_name = ['accuracy', 'precision', 'recall', 'f1-score','auc','fpr-score','tpr-score']\n",
    "#计算每个模型的评价指标值，然后按照模型名，指标名称将结果存入一个字典\n",
    "\n",
    "metrics = evaluate_textRNN_model(model, tf.convert_to_tensor(X_test_embedding), y_test)\n",
    "textRNN_metrics_dict = {metrics_name[j]: metrics[j] for j in range(len(metrics))}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eaf084389bdd2f1e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#以json文件保存字典结果\n",
    "with open('textRNN_metrics_dict.json', 'w') as f:\n",
    "    json.dump(textRNN_metrics_dict, f)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a671afe3d0468a2d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "model.save('textRNN_model.h5')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f670c8e2c8ab3b13"
  },
  {
   "cell_type": "markdown",
   "source": [
    "TxtRNN+attention模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d0cfcabcd70922c8"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)        [(None, 100, 128)]           0         []                            \n",
      "                                                                                                  \n",
      " lstm_8 (LSTM)               (None, 100, 128)             131584    ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, 100, 64)              8256      ['lstm_8[0][0]']              \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (None, 100, 64)              8256      ['lstm_8[0][0]']              \n",
      "                                                                                                  \n",
      " attention_5 (Attention)     (None, 100, 64)              0         ['dense_8[0][0]',             \n",
      "                                                                     'dense_9[0][0]']             \n",
      "                                                                                                  \n",
      " dense_10 (Dense)            (None, 100, 128)             8320      ['attention_5[0][0]']         \n",
      "                                                                                                  \n",
      " dense_11 (Dense)            (None, 100, 64)              8256      ['dense_10[0][0]']            \n",
      "                                                                                                  \n",
      " dense_12 (Dense)            (None, 100, 1)               65        ['dense_11[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 164737 (643.50 KB)\n",
      "Trainable params: 164737 (643.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T13:21:56.554593500Z",
     "start_time": "2024-03-30T13:21:55.662926200Z"
    }
   },
   "id": "a60695a84097a1d4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a0094b9d92e03672"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
