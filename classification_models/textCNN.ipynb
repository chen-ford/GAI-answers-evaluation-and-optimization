{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-28T08:31:49.426421100Z",
     "start_time": "2024-04-28T08:31:49.393485900Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from keras.src.layers import Embedding, Conv1D, MaxPooling1D, concatenate, Flatten, Dropout, Dense\n",
    "from keras import Input, Model\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#读取数据集\n",
    "X_train = pd.read_csv('data/X_train_minmaxscaler.csv')['ChatGPT回答'].iloc[:100]\n",
    "X_test = pd.read_csv('data/X_test_minmaxscaler.csv')['ChatGPT回答'].iloc[:100]\n",
    "y_train = pd.read_csv('data/y_train_minmaxscaler.csv').iloc[:100,:]\n",
    "y_test = pd.read_csv('data/y_test_minmaxscaler.csv').iloc[:100,:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T07:54:46.050283400Z",
     "start_time": "2024-04-28T07:54:39.140375100Z"
    }
   },
   "id": "63e7080cee8a1dd1"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "#处理数据\n",
    "\n",
    "cw = lambda x: list(jieba.cut(x))\n",
    "X_train_text = X_train.apply(cw)\n",
    "X_test_text = X_test.apply(cw)\n",
    "\n",
    "tokenizer=Tokenizer()  #创建一个Tokenizer对象\n",
    "#fit_on_texts函数可以将输入的文本中的每个词编号，编号是根据词频的，词频越大，编号越小\n",
    "tokenizer.fit_on_texts(X_train_text)\n",
    "tokenizer.fit_on_texts(X_test_text)\n",
    "vocab=tokenizer.word_index #得到每个词的编号\n",
    "\n",
    "# 将每个样本中的每个词转换为数字列表，使用每个词的编号进行编号\n",
    "X_train_word_ids=tokenizer.texts_to_sequences(X_train_text)\n",
    "X_test_word_ids = tokenizer.texts_to_sequences(X_test_text)\n",
    "#序列模式\n",
    "# 每条样本长度不唯一，将每条样本的长度设置一个固定值\n",
    "X_train_padded_seqs=pad_sequences(X_train_word_ids,maxlen=256) #将超过固定值的部分截掉，不足的在最前面用0填充\n",
    "X_test_padded_seqs=pad_sequences(X_test_word_ids, maxlen=256)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T08:03:22.153180Z",
     "start_time": "2024-04-28T08:03:21.869248700Z"
    }
   },
   "id": "7f44504f9dbd90b0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Smote不均衡采样\n",
    "from imblearn.over_sampling import SMOTE\n",
    "def smote(X_t, y_t):\n",
    "    # Create an instance of SMOTE\n",
    "    s = SMOTE(random_state=10)\n",
    "    # Apply SMOTE to the training data\n",
    "    X_train_resampled, y_train_resampled = s.fit_resample(X_t, y_t)\n",
    "    return X_train_resampled, y_train_resampled"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8fd9ef38d2ec5b8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#smote采样\n",
    "# X_train_padded_seqs, y_train = smote(X_train_padded_seqs, y_train)\n",
    "# X_test_padded_seqs, y_test = smote(X_test_padded_seqs, y_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b29661a58e9044f9"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#构建TextCNN模型\n",
    "#模型结构：词嵌入-卷积池化*3-拼接-全连接-dropout-全连接\n",
    "main_input = Input(shape=(256,), dtype='float64')\n",
    "# 词嵌入（使用预训练的词向量）\n",
    "embedder = Embedding(len(vocab) + 1, 300, input_length=256, trainable=False)\n",
    "embed = embedder(main_input)\n",
    "# 词窗大小分别为3,4,5\n",
    "cnn1 = Conv1D(256, 3, padding='same', strides=1, activation='relu')(embed)\n",
    "cnn1 = MaxPooling1D(pool_size=48)(cnn1)\n",
    "cnn2 = Conv1D(256, 4, padding='same', strides=1, activation='relu')(embed)\n",
    "cnn2 = MaxPooling1D(pool_size=47)(cnn2)\n",
    "cnn3 = Conv1D(256, 5, padding='same', strides=1, activation='relu')(embed)\n",
    "cnn3 = MaxPooling1D(pool_size=46)(cnn3)\n",
    "# 合并三个模型的输出向量\n",
    "cnn = concatenate([cnn1, cnn2, cnn3], axis=-1)\n",
    "flat = Flatten()(cnn)\n",
    "drop = Dropout(0.2)(flat)\n",
    "main_output = Dense(1, activation='sigmoid')(drop)\n",
    "model = Model(inputs=main_input, outputs=main_output)\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T10:56:37.471954100Z",
     "start_time": "2024-05-30T10:56:37.438434200Z"
    }
   },
   "id": "66f708b15f0b6644"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, logs):\n",
    "    # print(f'Epoch {epoch + 1}, Loss: {logs[\"loss\"]}') \n",
    "    print(f'Epoch {epoch + 1}')\n",
    "    train_loss = logs.get('loss')\n",
    "    val_loss = logs.get('val_loss')\n",
    "    train_acc = logs.get('accuracy')\n",
    "    val_acc = logs.get('val_accuracy')\n",
    "\n",
    "    print(f'Epoch {epoch + 1}, Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, '\n",
    "          f'Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}')\n",
    "    print(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T08:24:13.643711300Z",
     "start_time": "2024-04-28T08:24:13.626043300Z"
    }
   },
   "id": "67411074d5069550"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from keras.src.callbacks import LambdaCallback\n",
    "#训练模型\n",
    "# one_hot_labels = keras.utils.to_categorical(y_train, num_classes=3)  # 将标签转换为one-hot编码\n",
    "callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "history=model.fit(X_train_padded_seqs, y_train, batch_size=32, epochs=32,validation_split=0.2,callbacks=[callback])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T10:56:44.615514700Z",
     "start_time": "2024-05-30T10:56:44.566965700Z"
    }
   },
   "id": "1608d7852296ec63"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# 保存整个模型到一个HDF5文件  \n",
    "# model.save('textCNN_model.h5')  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T08:25:24.650000500Z",
     "start_time": "2024-04-28T08:25:24.620829700Z"
    }
   },
   "id": "97767154454ed11a"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# # 评估模型\n",
    "# score = model.evaluate(X_test_padded_seqs, y_test, verbose=0)  \n",
    "# print('Test loss:', score[0])  \n",
    "# print('Test accuracy:', score[1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T10:56:51.675886100Z",
     "start_time": "2024-05-30T10:56:51.624667900Z"
    }
   },
   "id": "d21d054bc49db624"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# loss = history.history['loss']  \n",
    "# val_loss = history.history['val_loss']\n",
    "#  \n",
    "# # 绘制训练和验证loss曲线  \n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(loss, label='Training Loss')  \n",
    "# plt.plot(val_loss, label='Validation Loss')  \n",
    "# plt.title('Loss Curve')  \n",
    "# plt.xlabel('Epoch')  \n",
    "# plt.ylabel('Loss')  \n",
    "# plt.legend()  \n",
    "# #保存loss曲线\n",
    "# # plt.savefig('txtCNN_loss_curve.png')\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T10:56:56.495354Z",
     "start_time": "2024-05-30T10:56:56.474575200Z"
    }
   },
   "id": "fbd9944a1b117ee3"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "#绘制准确率曲线\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(history.history['accuracy'])\n",
    "# plt.plot(history.history['val_accuracy'])\n",
    "# plt.title('Model Accuracy')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Validation'], loc='lower right')\n",
    "# # plt.savefig('txtCNN_accuracy.png')\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T10:57:52.671593500Z",
     "start_time": "2024-05-30T10:57:52.625499400Z"
    }
   },
   "id": "163e4d5d56c37d1c"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "#TextCNN模型的评价\n",
    "def evaluate_textCNN_model(model, X_test, y_test):\n",
    "\n",
    "    # Predict probabilities\n",
    "    y_pred_proba = model.predict(X_test)\n",
    "    \n",
    "    # Predict labels\n",
    "    y_pred=np.where(y_pred_proba>0.5,1,0)\n",
    "    \n",
    "    \n",
    "    # Calculate accuracy, precision, recall, F1-score, and AUC\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # Calculate ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "    \n",
    "    return [accuracy, precision, recall, f1, auc,fpr.tolist(), tpr.tolist()]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T08:32:26.284057700Z",
     "start_time": "2024-04-28T08:32:26.277194900Z"
    }
   },
   "id": "f6f73d5f3a4ff53b"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import json\n",
    "import tensorflow as tf\n",
    "#计算每个模型的评价指标,\n",
    "metrics_name = ['accuracy', 'precision', 'recall', 'f1-score','auc','fpr-score','tpr-score']\n",
    "#计算每个模型的评价指标值，然后按照模型名，指标名称将结果存入一个字典\n",
    "\n",
    "metrics = evaluate_textCNN_model(model, tf.convert_to_tensor(X_test_padded_seqs), y_test)\n",
    "textCNN_metrics_dict = {metrics_name[j]: metrics[j] for j in range(len(metrics))}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T10:58:00.549378100Z",
     "start_time": "2024-05-30T10:58:00.505510600Z"
    }
   },
   "id": "3bc55794fdb81ed1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#以json文件保存字典结果\n",
    "with open('textCNN_metrics_dict.json', 'w') as f:\n",
    "    json.dump(textCNN_metrics_dict, f)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c4d5cf0ec66b648"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
