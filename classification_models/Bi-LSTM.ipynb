{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Bi-LSTM模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "836af810b2bf35e"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score  \n",
    "from sklearn.metrics import roc_curve, auc  \n",
    "import matplotlib.pyplot as plt  \n",
    "import numpy as np  \n",
    "import tensorflow as tf\n",
    "from keras.layers import LSTM, Bidirectional, Dense, Attention\n",
    "from keras.models import Model\n",
    "import pandas as pd\n",
    "from keras.src.callbacks import LambdaCallback\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import torch\n",
    "from keras import optimizers\n",
    "import keras"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T17:10:34.861955200Z",
     "start_time": "2024-04-28T17:10:34.844019Z"
    }
   },
   "id": "ad14bc403bc4fad2"
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "# #均衡采样\n",
    "# def smote(X_train, y_train):\n",
    "#     # Create an instance of SMOTE\n",
    "#     smote = SMOTE(random_state=10)\n",
    "#     # Apply SMOTE to the training data\n",
    "#     X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "#     return X_train_resampled, y_train_resampled"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T18:41:16.840705500Z",
     "start_time": "2024-04-05T18:41:16.824118Z"
    }
   },
   "id": "e1b698eb5ae528c3"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    " # 加载训练集和测试集 \n",
    "\n",
    "y_train = pd.read_csv(r\"data_embedding_smote/y_train_smote.csv\")\n",
    "y_test = pd.read_csv(r\"data_embedding_smote/y_test_smote.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T12:53:57.813723500Z",
     "start_time": "2024-04-28T12:53:57.622026400Z"
    }
   },
   "id": "697140962c90d571"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "X_train_embedding=torch.load('data_embedding_smote/train_embedding_smote.pt',map_location=torch.device('cpu')).numpy()\n",
    "\n",
    "X_test_embedding=torch.load('data_embedding_smote/test_embedding_somte.pt',map_location=torch.device('cpu')).numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T12:54:13.974985600Z",
     "start_time": "2024-04-28T12:53:58.888549600Z"
    }
   },
   "id": "31e325cf982518c7"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# #smote采样\n",
    "# X_train_embedding,y_train = smote(X_train_embedding, y_train)\n",
    "# X_test_embedding,y_test = smote(X_test_embedding, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T04:23:30.602174400Z",
     "start_time": "2024-04-07T04:23:30.539927Z"
    }
   },
   "id": "a1302ba38cdce2e5"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "#改变数据形状\n",
    "X_train_embedding= torch.unsqueeze(torch.tensor(X_train_embedding),dim=1).numpy()\n",
    "X_test_embedding= torch.unsqueeze(torch.tensor(X_test_embedding),dim=1).numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T12:54:34.714915100Z",
     "start_time": "2024-04-28T12:54:33.324765600Z"
    }
   },
   "id": "48c80ce37f4befdb"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_4 (Bidirecti  (None, 1, 512)            2099200   \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " global_max_pooling1d_6 (Gl  (None, 512)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 128)               65664     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2173185 (8.29 MB)\n",
      "Trainable params: 2173185 (8.29 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 构建RCNN模型\n",
    "model = keras.Sequential([  \n",
    "    keras.layers.Input(shape=(1,768)),  \n",
    "    # keras.layers.LSTM(units=256,return_sequences=True), \n",
    "    Bidirectional(LSTM(256,return_sequences=True)),# LSTM层的输出默认是三维的(batch_size, timesteps, features)  \n",
    "    keras.layers.GlobalMaxPooling1D(),  # 现在可以安全地使用GlobalMaxPooling1D层  \n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "optimizer = keras.optimizers.legacy.Adam(learning_rate=0.0001,decay=1e-5)   #注意kaggle没有legacy\n",
    "model.compile(optimizer=optimizers.Adam(), loss='mean_squared_error', metrics=['accuracy'],run_eagerly=True)\n",
    "\n",
    "# 打印模型结构\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T17:10:41.016571300Z",
     "start_time": "2024-04-28T17:10:39.889446800Z"
    }
   },
   "id": "64ae324976a74a90"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# # 构建Bi-LSTM模型\n",
    "# # 定义输入层\n",
    "# input_layer = tf.keras.layers.Input(shape=(1,768))\n",
    "# #拉平向量\n",
    "# # flatten_layer = tf.keras.layers.Flatten()(input_layer)\n",
    "# # 构建Bi-LSTM模型\n",
    "# lstm_output = Bidirectional(LSTM(256))(input_layer)\n",
    "# #拉平向量\n",
    "# flatten_layer = tf.keras.layers.Flatten()(lstm_output)\n",
    "# # 添加全连接层\n",
    "# dense_output1 = Dense(128, activation='relu')(flatten_layer)\n",
    "# dense_output2 = Dense(64, activation='relu')(dense_output1)\n",
    "# \n",
    "# output= Dense(1, activation='sigmoid')(dense_output2)\n",
    "# \n",
    "# \n",
    "# model = Model(inputs=input_layer, outputs=output)\n",
    "# optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.0001,decay=1e-5)   #注意kaggle没有legacy\n",
    "# model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['accuracy'],run_eagerly=True)\n",
    "# \n",
    "# # 打印模型结构\n",
    "# model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T04:24:49.982324300Z",
     "start_time": "2024-04-07T04:24:49.919291700Z"
    }
   },
   "id": "29d966e6c7fef633"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# import keras\n",
    "# \n",
    "# # 注意力机制层  \n",
    "# @keras.saving.register_keras_serializable(package=\"custom_objects\")\n",
    "# class Attention(keras.layers.Layer):\n",
    "#     def __init__(self, units, **kwargs):\n",
    "#         super(Attention, self).__init__()\n",
    "#         self.W = keras.layers.Dense(units)\n",
    "#         self.V = keras.layers.Dense(1)\n",
    "# \n",
    "#     def call(self, inputs):\n",
    "#         query = inputs[0]\n",
    "#         values = inputs[1]\n",
    "# \n",
    "#         query_with_time_axis = tf.expand_dims(query, 1)\n",
    "# \n",
    "#         score = tf.nn.tanh(self.W(query_with_time_axis) + self.W(values))\n",
    "#         attention_weights = tf.nn.softmax(self.V(score), axis=1)\n",
    "# \n",
    "#         context_vector = attention_weights * values\n",
    "#         context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "# \n",
    "#         return context_vector\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T03:12:53.161439700Z",
     "start_time": "2024-04-08T03:12:53.112370500Z"
    }
   },
   "id": "cd862df19cd438b8"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mi\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "WARNING:tensorflow:From C:\\Users\\mi\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 1, 768)]             0         []                            \n",
      "                                                                                                  \n",
      " bidirectional (Bidirection  (None, 512)                  2099200   ['input_1[0][0]']             \n",
      " al)                                                                                              \n",
      "                                                                                                  \n",
      " attention (Attention)       (None, 512)                  131585    ['bidirectional[0][0]',       \n",
      "                                                                     'bidirectional[0][0]']       \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 128)                  65664     ['attention[0][0]']           \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 64)                   8256      ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 32)                   2080      ['dense_3[0][0]']             \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 1)                    33        ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2306818 (8.80 MB)\n",
      "Trainable params: 2306818 (8.80 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# # 构建Bi-LSTM-attention模型\n",
    "# # 定义输入层\n",
    "# input_layer = keras.layers.Input(shape=(1,768))\n",
    "# #拉平向量\n",
    "# # flatten_layer = tf.keras.layers.Flatten()(input_layer)\n",
    "# \n",
    "# # 构建Bi-LSTM模型\n",
    "# lstm_output = Bidirectional(LSTM(256))(input_layer)\n",
    "# #拉平向量\n",
    "# # flatten_layer = tf.keras.layers.Flatten()(lstm_output)\n",
    "# \n",
    "# #添加注意力层\n",
    "# attention_output = Attention(256)([lstm_output, lstm_output])\n",
    "# \n",
    "# # 添加全连接层\n",
    "# dense_output1 = Dense(128, activation='relu')(attention_output)\n",
    "# dense_output2 = Dense(64, activation='relu')(dense_output1)\n",
    "# dense_output3 = Dense(32, activation='relu')(dense_output2)\n",
    "# output= Dense(1, activation='sigmoid')(dense_output3)\n",
    "# \n",
    "# model = Model(inputs=input_layer, outputs=output)\n",
    "# # optimizer = keras.optimizers.legacy.Adam(learning_rate=0.0001)#注意kaggle没有legacy\n",
    "# model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'],run_eagerly=True)\n",
    "# \n",
    "# # 打印模型结构\n",
    "# model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T03:13:00.805940300Z",
     "start_time": "2024-04-08T03:12:56.171047100Z"
    }
   },
   "id": "b2835d82a0e0ccdc"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, logs):  \n",
    "\n",
    "    # print(f'Epoch {epoch + 1}, Loss: {logs[\"loss\"]}') \n",
    "    print(f'Epoch {epoch + 1}') \n",
    "    train_loss = logs.get('loss')  \n",
    "    val_loss = logs.get('val_loss')  \n",
    "    train_acc = logs.get('accuracy')  \n",
    "    val_acc = logs.get('val_accuracy')  \n",
    "      \n",
    "    print(f'Epoch {epoch + 1}, Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, '  \n",
    "          f'Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}')  \n",
    "    print(\"\\n\")\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T12:55:00.901366300Z",
     "start_time": "2024-04-28T12:55:00.857685600Z"
    }
   },
   "id": "1975f1cacd9ba7c2"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# 将标签转换为one-hot编码\n",
    "# y_one_hot = tf.keras.utils.to_categorical(y_train, num_classes=2)\n",
    "# 训练模型\n",
    "callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "history = model.fit(tf.convert_to_tensor(X_train_embedding), y_train, epochs=32,shuffle=True, validation_split=0.2, batch_size=32, callbacks=[callback])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T09:24:22.668317900Z",
     "start_time": "2024-05-30T09:24:22.661733200Z"
    }
   },
   "id": "5410727bbd2d840d"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#绘制loss曲线\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('Model Loss')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "# # plt.savefig('Bert_Bi-LSTM_Attention_loss.png')\n",
    "# plt.savefig('RCNN_loss.png')\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T09:24:35.364941200Z",
     "start_time": "2024-05-30T09:24:31.449078500Z"
    }
   },
   "id": "145580ff5787eef6"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#绘制准确率曲线\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(history.history['accuracy'])\n",
    "# plt.plot(history.history['val_accuracy'])\n",
    "# plt.title('Model Accuracy')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Validation'], loc='lower right')\n",
    "# # plt.savefig('Bert_Bi-LSTM_Attention_accuracy.png')\n",
    "# plt.savefig('RCNN_accuracy.png')\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T09:24:43.671594900Z",
     "start_time": "2024-05-30T09:24:43.645004800Z"
    }
   },
   "id": "1cb7067ebefce146"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "#使用tensorflow保存\n",
    "model.save('RCNN.keras')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T17:08:48.802887800Z",
     "start_time": "2024-04-07T17:08:46.170396500Z"
    }
   },
   "id": "5b6bf4275f368f7f"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# 评估模型\n",
    "# score = model.evaluate(X_test_embedding, y_test, verbose=0)  \n",
    "# print('Test loss:', score[0])  \n",
    "# print('Test accuracy:', score[1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T09:24:48.817957200Z",
     "start_time": "2024-05-30T09:24:48.788963200Z"
    }
   },
   "id": "c1cd064684b4ca8a"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "#bert_bi-lstm模型的评价\n",
    "def evaluate_bert_bilstm_model(model, X_test, y_test):\n",
    "\n",
    "    # Predict probabilities\n",
    "    y_pred_proba = model.predict(X_test)\n",
    "    \n",
    "    # Predict labels\n",
    "    y_pred=np.where(y_pred_proba>0.5,1,0)\n",
    "    \n",
    "    # Calculate accuracy, precision, recall, F1-score, and AUC\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # Calculate ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "    \n",
    "    return [accuracy, precision, recall, f1, auc,fpr.tolist(), tpr.tolist()]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T08:51:04.509339300Z",
     "start_time": "2024-04-08T08:51:04.472795600Z"
    }
   },
   "id": "3e101b7ad414d127"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# #计算模型的评价指标\n",
    "metrics_name = ['accuracy', 'precision', 'recall', 'f1-score','auc','fpr-score','tpr-score']\n",
    "#计算每个模型的评价指标值，然后按照模型名，指标名称将结果存入一个字典\n",
    "metrics = evaluate_bert_bilstm_model(model, tf.convert_to_tensor(X_test_embedding), y_test)\n",
    "# bert_bilstm_metrics_dict = {metrics_name[j]: metrics[j] for j in range(len(metrics))} \n",
    "RCNN_metrics_dict = {metrics_name[j]: metrics[j] for j in range(len(metrics))} "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T09:25:06.841069500Z",
     "start_time": "2024-05-30T09:25:06.807107200Z"
    }
   },
   "id": "2d1d1b83bdfe4a6d"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "#以json文件保存字典结果\n",
    "with open('RCNN_metrics_dict.json', 'w') as f:\n",
    "    json.dump(RCNN_metrics_dict, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T17:13:07.993302100Z",
     "start_time": "2024-04-07T17:13:07.899638700Z"
    }
   },
   "id": "12f70791a9479398"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "715069f4f3266d79"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
