{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 7923855,
     "sourceType": "datasetVersion",
     "datasetId": 4656784
    },
    {
     "sourceId": 7927184,
     "sourceType": "datasetVersion",
     "datasetId": 4658905
    },
    {
     "sourceId": 7931395,
     "sourceType": "datasetVersion",
     "datasetId": 4661991
    }
   ],
   "dockerImageVersionId": 30673,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# pip install snownlp"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-24T16:23:26.513521Z",
     "iopub.execute_input": "2024-03-24T16:23:26.514066Z",
     "iopub.status.idle": "2024-03-24T16:23:55.707814Z",
     "shell.execute_reply.started": "2024-03-24T16:23:26.514027Z",
     "shell.execute_reply": "2024-03-24T16:23:55.706267Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-05-30T10:59:39.509393200Z",
     "start_time": "2024-05-30T10:59:39.490939400Z"
    }
   },
   "execution_count": 1,
   "outputs": [],
   "id": "dff5a97e6709f721"
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import jieba\n",
    "import jieba.posseg as pseg  \n",
    "from snownlp import SnowNLP "
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-24T16:24:21.869050Z",
     "iopub.execute_input": "2024-03-24T16:24:21.869537Z",
     "iopub.status.idle": "2024-03-24T16:24:21.878209Z",
     "shell.execute_reply.started": "2024-03-24T16:24:21.869501Z",
     "shell.execute_reply": "2024-03-24T16:24:21.876394Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": [],
   "id": "f19eb79f425ef25b"
  },
  {
   "cell_type": "code",
   "source": [
    "#读取停用词\n",
    "folder_path = \"/kaggle/input/stopwords\"\n",
    "stopwords = []\n",
    "try:\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(\".txt\"):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                s = file.readlines()\n",
    "                # print(f\"文件名: {file_name}\")\n",
    "                stopwords+=s\n",
    "                \n",
    "                # print(\"----------------------\")\n",
    "except FileNotFoundError:\n",
    "    print(\"找不到指定的文件夹，请检查文件夹路径是否正确。\")\n",
    "except Exception as e:\n",
    "    print(\"发生错误:\", e)\n",
    "stopwords = [word.replace('\\n', '') for word in stopwords]\n",
    "# print(stopwords)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T16:02:29.727570500Z",
     "start_time": "2024-03-24T16:02:29.195800300Z"
    },
    "execution": {
     "iopub.status.busy": "2024-03-24T16:24:31.197286Z",
     "iopub.execute_input": "2024-03-24T16:24:31.197767Z",
     "iopub.status.idle": "2024-03-24T16:24:31.224868Z",
     "shell.execute_reply.started": "2024-03-24T16:24:31.197728Z",
     "shell.execute_reply": "2024-03-24T16:24:31.223856Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": [],
   "id": "a78fb605d455a867"
  },
  {
   "cell_type": "code",
   "source": [
    "# 医学术语列表\n",
    "def Medicalwordslist(filepath2):  # 创建专业医学词汇列表\n",
    "    pattern = re.compile(r'[^\\u4e00-\\u9fa5]')\n",
    "    Medicalword = [re.sub(pattern, \"\", line.strip().replace(\" \", '')) for line in open(filepath2, 'r', encoding=\"utf-8\").readlines()]  # 以行的形式读取停用词表，同时转换为列表\n",
    "    return Medicalword\n",
    "medicalword = Medicalwordslist(r'/kaggle/input/medical-terms/all_medical_terms.txt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T16:02:30.985416Z",
     "start_time": "2024-03-24T16:02:29.220214100Z"
    },
    "execution": {
     "iopub.status.busy": "2024-03-24T16:24:36.717612Z",
     "iopub.execute_input": "2024-03-24T16:24:36.718002Z",
     "iopub.status.idle": "2024-03-24T16:24:38.980439Z",
     "shell.execute_reply.started": "2024-03-24T16:24:36.717970Z",
     "shell.execute_reply": "2024-03-24T16:24:38.979030Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": [],
   "id": "e39f012d3b5fe67"
  },
  {
   "cell_type": "markdown",
   "source": [
    "特征提取函数"
   ],
   "metadata": {},
   "id": "235027e07f47c989"
  },
  {
   "cell_type": "code",
   "source": [
    "# 文本长度\n",
    "def count_text_length(text):\n",
    "    return len(text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T16:02:31.001012700Z",
     "start_time": "2024-03-24T16:02:30.990421600Z"
    }
   },
   "execution_count": 87,
   "outputs": [],
   "id": "c785986994ef842d"
  },
  {
   "cell_type": "code",
   "source": [
    "#句子数\n",
    "def count_num_sentences(text):\n",
    "    # 使用正则表达式匹配中文句号、问号、感叹号作为句子的结束符号\n",
    "    pattern = r'[\\u4e00-\\u9fa5][。？！]'\n",
    "    sentences = re.findall(pattern, text)\n",
    "    \n",
    "    # 最后一句可能没有结束符号，需要额外判断\n",
    "    if len(text) > 0 or text[-1] in '。？！':\n",
    "        sentences.append(text[-1])\n",
    "    \n",
    "    return len(sentences)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T16:02:31.060085400Z",
     "start_time": "2024-03-24T16:02:30.998972900Z"
    }
   },
   "execution_count": 88,
   "outputs": [],
   "id": "6a41f565f593eb36"
  },
  {
   "cell_type": "code",
   "source": [
    "# 单词数量\n",
    "def count_num_words(text):\n",
    "    # 使用正则表达式去除标点符号\n",
    "    text = re.sub(r'[^\\u4e00-\\u9fa5]', '', text)\n",
    "   \n",
    "    # 使用结巴分词对中文文本进行分词\n",
    "    words = jieba.lcut(text, cut_all=True)\n",
    "    \n",
    "    # 去除空格等无意义字符\n",
    "    words = [word for word in words if word.strip()]\n",
    "\n",
    "    return len(words)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T16:02:31.060784400Z",
     "start_time": "2024-03-24T16:02:31.030542100Z"
    }
   },
   "execution_count": 89,
   "outputs": [],
   "id": "185191be1471f3a0"
  },
  {
   "cell_type": "code",
   "source": [
    "#停用词数\n",
    "def count_num_stopwords(text,stopwords=stopwords):\n",
    "    # 使用正则表达式去除标点符号\n",
    "    text = re.sub(r'[^\\u4e00-\\u9fa5]', '', text)   \n",
    "    # 使用结巴分词对中文文本进行分词\n",
    "    words = jieba.lcut(text, cut_all=True)    \n",
    "    # 去除空格等无意义字符\n",
    "    words = [word for word in words if word.strip()]\n",
    "    # 计算停用词数\n",
    "    stop_words = [word for word in words if word  in stopwords]\n",
    "    return len(stop_words)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T16:06:44.075591200Z",
     "start_time": "2024-03-24T16:06:44.051649600Z"
    }
   },
   "execution_count": 110,
   "outputs": [],
   "id": "f0f0731f26cf8152"
  },
  {
   "cell_type": "code",
   "source": [
    "# 标点符号数\n",
    "def count_num_punctuation(text):  \n",
    "    # 常见的中文标点符号列表  \n",
    "    chinese_punctuation = '，。！？；：“”、（）《》「」【】『』｛｝……'  \n",
    "      \n",
    "    # 初始化计数器  \n",
    "    count = 0  \n",
    "      \n",
    "    # 遍历文本的每个字符  \n",
    "    for char in text:  \n",
    "        # 如果字符在中文标点符号列表中，则计数器加1  \n",
    "        if char in chinese_punctuation:  \n",
    "            count += 1  \n",
    "      \n",
    "    # 返回标点符号数量  \n",
    "    return count  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T16:02:31.111965700Z",
     "start_time": "2024-03-24T16:02:31.058348200Z"
    }
   },
   "execution_count": 91,
   "outputs": [],
   "id": "a27a7eac458c4bed"
  },
  {
   "cell_type": "code",
   "source": [
    "# 短句数量\n",
    "def count_num_shortsentences(text, max_length=20):  \n",
    "    # 句末标点符号列表  \n",
    "    sentence_ending_punctuation = '，。！？；：“”、（）《》「」【】『』｛｝……'  \n",
    "      \n",
    "    # 使用正则表达式来匹配句末标点符号，并分割文本为句子列表  \n",
    "    sentences = re.split(r'[{}]+'.format(re.escape(sentence_ending_punctuation)), text)  \n",
    "    sentences=sentences[:-1]\n",
    "    # 过滤并计数字符数在max_length以下的句子  \n",
    "    short_sentence_count = sum([1 for s in sentences if len(s.strip()) <= max_length])  \n",
    "      \n",
    "    # 返回短句数量  \n",
    "    return short_sentence_count  \n",
    "  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T16:06:54.150961300Z",
     "start_time": "2024-03-24T16:06:54.133309Z"
    }
   },
   "execution_count": 111,
   "outputs": [],
   "id": "cc7166cabc11e6fd"
  },
  {
   "cell_type": "code",
   "source": [
    "# 形容词数\n",
    "def count_num_adjectives(text):  \n",
    "    # 使用jieba的词性标注功能  \n",
    "    words = pseg.cut(text)  \n",
    "    \n",
    "    # 定义形容词的词性标签集合  \n",
    "    # 'a' 代表形容词  \n",
    "    adjective_tags = ['a', 'ad', 'an', 'ag', 'al']  \n",
    "      \n",
    "    # 初始化形容词计数器  \n",
    "    adjective_count = 0  \n",
    "      \n",
    "    # 遍历每个词和对应的词性  \n",
    "    for word, flag in words:  \n",
    "        # 如果词性标签在形容词标签集合中，则增加计数器  \n",
    "        if flag in adjective_tags:  \n",
    "            adjective_count += 1  \n",
    "      \n",
    "    # 返回形容词数量  \n",
    "    return adjective_count  \n",
    "  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T16:02:31.142977500Z",
     "start_time": "2024-03-24T16:02:31.093702700Z"
    }
   },
   "execution_count": 93,
   "outputs": [],
   "id": "31b2845a764118ee"
  },
  {
   "cell_type": "code",
   "source": [
    "# 副词数\n",
    "def count_num_adverbs(text):  \n",
    "    # 使用jieba的词性标注功能  \n",
    "    words = pseg.cut(text)  \n",
    "      \n",
    "    # 定义副词的词性标签  \n",
    "    adverb_tags = ['d', 'df', 'dg']\n",
    "      \n",
    "    # 初始化副词计数器  \n",
    "    adverb_count = 0  \n",
    "      \n",
    "    # 遍历每个词和对应的词性  \n",
    "    for word, flag in words:  \n",
    "        # 如果词性标签是副词标签，则增加计数器  \n",
    "        if flag in adverb_tags:  \n",
    "            adverb_count += 1  \n",
    "      \n",
    "    # 返回副词数量  \n",
    "    return adverb_count  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T16:02:31.169180800Z",
     "start_time": "2024-03-24T16:02:31.113369900Z"
    }
   },
   "execution_count": 94,
   "outputs": [],
   "id": "3650e0362dcea66"
  },
  {
   "cell_type": "code",
   "source": [
    "# 名词数\n",
    "def count_num_nouns(text):  \n",
    "    # 使用jieba进行分词和词性标注  \n",
    "    words = pseg.cut(text)\n",
    "    \n",
    "    noun_count = 0  \n",
    "    noun = ['n', 'nr', 'nr1', 'nr2', 'nrj', 'ns', 'nsf', 'nt', 'nz', 'nl', 'nx', 'ng', 'nrt', 'nrfg']\n",
    "    # 遍历分词结果，统计名词数量  \n",
    "    for word, flag in words:  \n",
    "        # 'n' 在jieba中表示名词  \n",
    "        if flag in noun:  \n",
    "            noun_count += 1  \n",
    "      \n",
    "    return noun_count  \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T16:02:31.206220700Z",
     "start_time": "2024-03-24T16:02:31.132240800Z"
    }
   },
   "execution_count": 95,
   "outputs": [],
   "id": "e5b0406523f97389"
  },
  {
   "cell_type": "code",
   "source": [
    "# 动词数\n",
    "def count_num_verbs(text):  \n",
    "    # 使用jieba的词性标注功能  \n",
    "    words = pseg.cut(text)  \n",
    "   \n",
    "    # 定义动词的词性标签  \n",
    "    verb = ['v', 'vd', 'vg', 'vi', 'vn', 'vq', 'vshi', 'vyou', 'vf', 'vx', 'vl']\n",
    "    \n",
    "    # 初始化动词计数器  \n",
    "    verb_count = 0  \n",
    "      \n",
    "    # 遍历每个词和对应的词性  \n",
    "    for word, flag in words:  \n",
    "        # 如果词性标签是动词标签，则增加计数器  \n",
    "        if flag in verb:  \n",
    "            verb_count += 1  \n",
    "      \n",
    "    # 返回动词数量  \n",
    "    return verb_count  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T16:02:31.210807700Z",
     "start_time": "2024-03-24T16:02:31.145976200Z"
    }
   },
   "execution_count": 96,
   "outputs": [],
   "id": "18c69e5e352e1cae"
  },
  {
   "cell_type": "code",
   "source": [
    "# 答案关键词数\t\n",
    "def count_num_keywords(text, stopwords=stopwords):\n",
    "    # 使用正则表达式去除标点符号\n",
    "    text = re.sub(r'[^\\u4e00-\\u9fa5]', '', text)\n",
    "    \n",
    "    # 使用结巴分词对中文文本进行分词\n",
    "    words = jieba.lcut(text,cut_all=True)\n",
    "    \n",
    "    # 去除停用词\n",
    "    words = [word for word in words if word.strip() and word not in stopwords]\n",
    "    \n",
    "    return len(words)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T16:02:31.299429100Z",
     "start_time": "2024-03-24T16:02:31.159586400Z"
    }
   },
   "execution_count": 97,
   "outputs": [],
   "id": "8a184102e14ecbb8"
  },
  {
   "cell_type": "code",
   "source": [
    "# 文本信息熵\n",
    "def calculate_entropy(text,stopwords=stopwords):\n",
    "    # 使用正则表达式去除标点符号\n",
    "    text = re.sub(r'[^\\u4e00-\\u9fa5]', '', text)\n",
    "    # 使用结巴分词对中文文本进行分词\n",
    "    words = jieba.lcut(text, cut_all=True)\n",
    "    # 去除停用词\n",
    "    words = list(set([word for word in words if word.strip() and word not in stopwords]))\n",
    "    \n",
    "    char_freq = {}\n",
    "    total_chars = 0\n",
    "    entropy = 0.0\n",
    "\n",
    "    # 统计每个字符出现的频率\n",
    "    for char in words:\n",
    "        if char in char_freq:\n",
    "            char_freq[char] += 1\n",
    "        else:\n",
    "            char_freq[char] = 1\n",
    "        total_chars += 1\n",
    "\n",
    "    # 计算信息熵\n",
    "    for freq in char_freq.values():\n",
    "        probability = freq / total_chars\n",
    "        entropy -= probability * math.log(probability, 2)\n",
    "\n",
    "    return round(entropy,4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T16:02:31.299429100Z",
     "start_time": "2024-03-24T16:02:31.175387200Z"
    }
   },
   "execution_count": 98,
   "outputs": [],
   "id": "df9e144e0f3185c3"
  },
  {
   "cell_type": "code",
   "source": [
    "# 医学术语数\n",
    "def count_num_medicalwords(text,stopwords=stopwords,medicalword=medicalword):\n",
    "    Medicalword =medicalword\n",
    "    # 去除标点符号和停用词\n",
    "    text = re.sub(r'[^\\u4e00-\\u9fa5]', '', text)\n",
    "    \n",
    "    # 使用结巴分词对中文文本进行分词\n",
    "    words = jieba.lcut(text, cut_all=True)\n",
    "    \n",
    "    # 去除停用词\n",
    "    words = list(set([word for word in words if word.strip() and word not in stopwords]))\n",
    "    \n",
    "    medicalwords = []  # 医学专业词的总长度\n",
    "    for word in words:\n",
    "        if word in Medicalword: \n",
    "            # print(\"word:\", word)\n",
    "            medicalwords.append(word)\n",
    "    \n",
    "    return len(medicalwords)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T16:07:55.704770500Z",
     "start_time": "2024-03-24T16:07:55.692108Z"
    }
   },
   "execution_count": 112,
   "outputs": [],
   "id": "bf3e3f30679aa97b"
  },
  {
   "cell_type": "code",
   "source": [
    "# 医学术语与文本关键词数比值\n",
    "def density_medicalwords(num_keywords,num_medicalwords):\n",
    "    \n",
    "    return round(num_medicalwords/num_keywords,3)\n",
    "    # 去除停用词 "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T16:02:31.333893700Z",
     "start_time": "2024-03-24T16:02:31.219630400Z"
    }
   },
   "execution_count": 100,
   "outputs": [],
   "id": "8510427f88b2c0bd"
  },
  {
   "cell_type": "code",
   "source": [
    "# 问题和答案关键词重合度\n",
    "def extract_keywords(text,stopwords=stopwords):  \n",
    "    # 使用正则表达式去除标点符号\n",
    "    text = re.sub(r'[^\\u4e00-\\u9fa5]', '', text)\n",
    "    \n",
    "    # 使用结巴分词对中文文本进行分词\n",
    "    words = jieba.lcut(text,cut_all=True)\n",
    "    \n",
    "    # 去除停用词\n",
    "    words = [word for word in words if word.strip() and word not in stopwords]\n",
    "    # print(words)\n",
    "    return words\n",
    "  \n",
    "def calculate_keyword_overlap(text1, text2):  \n",
    "    \"\"\"  \n",
    "    计算两段文本的关键词重合度  \n",
    "    :param text1: 第一段文本  \n",
    "    :param text2: 第二段文本  \n",
    "    :return: 关键词重合度  \n",
    "    \"\"\"  \n",
    "    # 提取关键词  \n",
    "    keywords1 = extract_keywords(text1)  \n",
    "    keywords2 = extract_keywords(text2)  \n",
    "      \n",
    "    # 计算重合的关键词数量  \n",
    "    overlap = len(set(keywords1) & set(keywords2))  \n",
    "      \n",
    "    # 计算总的关键词数量（去除重复）  \n",
    "    total = len(set(keywords1) | set(keywords2))  \n",
    "      \n",
    "    # 计算重合度  \n",
    "    overlap_rate = overlap / total if total > 0 else 0  \n",
    "      \n",
    "    return round(overlap_rate,3)  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T16:02:31.356787900Z",
     "start_time": "2024-03-24T16:02:31.235592300Z"
    }
   },
   "execution_count": 101,
   "outputs": [],
   "id": "fa4bfff9a9a3cc20"
  },
  {
   "cell_type": "code",
   "source": [
    "# 问题和答案语义相似性\n",
    "def calculate_semantic_similarity():\n",
    "    return 0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T16:02:31.357816500Z",
     "start_time": "2024-03-24T16:02:31.248784300Z"
    }
   },
   "execution_count": 102,
   "outputs": [],
   "id": "d9efd107fd1169e6"
  },
  {
   "cell_type": "code",
   "source": [
    "# 积极情感词数\n",
    "def count_num_positive_words(text,stopwords=stopwords):\n",
    "    # 去除标点符号和停用词\n",
    "    text = re.sub(r'[^\\u4e00-\\u9fa5]', '', text)\n",
    "        \n",
    "    # 使用结巴分词对中文文本进行分词\n",
    "    words = jieba.lcut(text)\n",
    "    # 去除停用词\n",
    "    words = [word for word in words if word.strip() and word not in stopwords]\n",
    "    \n",
    "    # 初始化积极情感词计数器  \n",
    "    positive_word_count = 0  \n",
    "      \n",
    "    # 遍历每个词，尝试进行情感分析  \n",
    "    for word in words:  \n",
    "        # 注意：这里假设SnowNLP的sentiment方法返回的情感分数越高，表示越积极  \n",
    "        # 但实际上，SnowNLP的sentiment方法通常用于判断整个句子的情感倾向，而不是单个词  \n",
    "        sentiment_score = SnowNLP(word).sentiments \n",
    "          \n",
    "        # 设定一个阈值，认为情感分数大于这个阈值的词为积极情感词  \n",
    "        threshold = 0.5  # 这个阈值需要根据实际情况进行调整  \n",
    "        if sentiment_score > threshold:\n",
    "            # print(word)\n",
    "            positive_word_count += 1  \n",
    "    \n",
    "    return positive_word_count"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T16:09:09.665529300Z",
     "start_time": "2024-03-24T16:09:09.601605100Z"
    }
   },
   "execution_count": 118,
   "outputs": [],
   "id": "90f75f0f917de94f"
  },
  {
   "cell_type": "code",
   "source": [
    "# 消极情感词数\n",
    "def count_num_negative_words(text,stopwords=stopwords):\n",
    "    text = re.sub(r'[^\\u4e00-\\u9fa5]', '', text)\n",
    "        \n",
    "    # 使用结巴分词对中文文本进行分词\n",
    "    words = jieba.lcut(text)\n",
    "    # 去除停用词\n",
    "    words = [word for word in words if word.strip() and word not in stopwords]\n",
    "    \n",
    "    # 初始化积极情感词计数器  \n",
    "    negative_word_count = 0  \n",
    "      \n",
    "    # 遍历每个词，尝试进行情感分析  \n",
    "    for word in words:  \n",
    "        # 注意：这里假设SnowNLP的sentiment方法返回的情感分数越高，表示越积极  \n",
    "        # 但实际上，SnowNLP的sentiment方法通常用于判断整个句子的情感倾向，而不是单个词  \n",
    "        sentiment_score = SnowNLP(word).sentiments \n",
    "          \n",
    "        # 设定一个阈值，认为情感分数大于这个阈值的词为积极情感词  \n",
    "        threshold = 0.5  # 这个阈值需要根据实际情况进行调整  \n",
    "        if sentiment_score < threshold:\n",
    "            # print(word)\n",
    "            negative_word_count += 1  \n",
    "    \n",
    "    return negative_word_count"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T16:09:04.575776100Z",
     "start_time": "2024-03-24T16:09:04.542685900Z"
    }
   },
   "execution_count": 117,
   "outputs": [],
   "id": "a27573a0ebe9a169"
  },
  {
   "cell_type": "code",
   "source": [
    "# 情感极性\n",
    "def calculate_sentiment_polarity(text):\n",
    "    text = re.sub(r'[^\\u4e00-\\u9fa5]', '', text)\n",
    "    s= SnowNLP(text)\n",
    "    \n",
    "    return round(s.sentiments,5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T16:08:15.589491200Z",
     "start_time": "2024-03-24T16:08:15.560981Z"
    }
   },
   "execution_count": 115,
   "outputs": [],
   "id": "86ae2618985ac241"
  },
  {
   "cell_type": "markdown",
   "source": [
    "特征量化"
   ],
   "metadata": {},
   "id": "c424ca3e00c882cf"
  },
  {
   "cell_type": "code",
   "source": [
    "#函数进行特征提取\n",
    "def feature_extraction(question,answer):\n",
    "    #文本长度\n",
    "    len_text=count_text_length(answer)\n",
    "    #句子数\n",
    "    num_sentences=count_num_sentences(answer)\n",
    "    #单词数\n",
    "    num_words=count_num_words(answer)\n",
    "    #停用词数量\n",
    "    num_stopwords=count_num_stopwords(answer)\n",
    "    #标点符号数\n",
    "    num_punctuations=count_num_punctuation(answer)\n",
    "    #短句数\n",
    "    num_short_sentences=count_num_shortsentences(answer)\n",
    "    #形容词数\n",
    "    num_adjectives=count_num_adjectives(answer)\n",
    "    #动词数\n",
    "    num_verbs=count_num_verbs(answer)\n",
    "    #名词数\n",
    "    num_nouns=count_num_nouns(answer)\n",
    "    #动词数\n",
    "    num_adverbs=count_num_adverbs(answer)\n",
    "    #关键词数\n",
    "    num_keywords=count_num_keywords(answer)\n",
    "    #文本信息熵\n",
    "    text_entropy=calculate_entropy(answer)\n",
    "    #医学术语数量\n",
    "    num_medical_terms=count_num_medicalwords(answer)\n",
    "    #医学术语与关键词比例\n",
    "    medical_keywords_ratio=density_medicalwords(num_keywords,num_medical_terms)\n",
    "    #问题和答案关键词重合度\n",
    "    keywords_overlap=calculate_keyword_overlap(question,answer)\n",
    "    # 语义相似度\n",
    "    semantic_similarity=calculate_semantic_similarity()\n",
    "    # 积极情感词数\n",
    "    num_positive_words=count_num_positive_words(answer)\n",
    "    # 消极情感词数\n",
    "    num_native_words=count_num_negative_words(answer)\n",
    "    # 情感极性\n",
    "    sentiment_polarity=calculate_sentiment_polarity(answer)\n",
    "    \n",
    "    return [len_text,num_sentences,num_words,num_stopwords,num_punctuations,num_short_sentences,num_adjectives,num_verbs,num_nouns,num_adverbs,num_keywords,text_entropy,num_medical_terms,medical_keywords_ratio,keywords_overlap,semantic_similarity,num_positive_words,num_native_words,sentiment_polarity]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T16:02:31.428803500Z",
     "start_time": "2024-03-24T16:02:31.318391900Z"
    }
   },
   "execution_count": 106,
   "outputs": [],
   "id": "e69ac47447d25a67"
  },
  {
   "cell_type": "code",
   "source": [
    "# data = pd.read_csv('/kaggle/input/chatgpt/chatGPT.csv')\n",
    "# data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T10:59:54.396537600Z",
     "start_time": "2024-05-30T10:59:54.318739600Z"
    }
   },
   "execution_count": 2,
   "outputs": [],
   "id": "39e02b4e61114695"
  },
  {
   "cell_type": "code",
   "source": [
    "# df=pd.DataFrame(columns=['len_text','num_sentences','num_words','num_stopwords','num_punctuations','num_short_sentences','num_adjectives','num_verbs','num_nouns','num_adverbs','num_keywords','text_entropy','num_medical_terms','medical_keywords_ratio','keywords_overlap','semantic_similarity','num_positive_words','num_native_words','sentiment_polarity'])\n",
    "# for i in range(len(data)):\n",
    "#     df.loc[i]=feature_extraction(data['问题'][i],data['ChatGPT回答'][i])\n",
    "# df.to_csv('chatGPT_data_feature.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-30T11:00:06.999184300Z",
     "start_time": "2024-05-30T11:00:06.913050900Z"
    }
   },
   "execution_count": 3,
   "outputs": [],
   "id": "83600ed8b762db92"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "57dac28784214804"
  }
 ]
}
